{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_2017.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s2akbarp/NWT-land-Cover-Classification/blob/main/Classification_2017.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_P3bPmCKn_L"
      },
      "source": [
        "Shae Akbarpour https://github.com/s2akbarp\n",
        "\n",
        "Using Neural network and mechine learning algorithm for classification of land covers in discontinous permafrost regions of NWT.\n",
        "=============================================================\n",
        "Here We used:\n",
        "The World View(WV) 2 (2010) Image will be used to classify the primary land covers in NWT \n",
        "       1: Fen\n",
        "       2:Permafrost plateaus\n",
        "       3: Bogs\n",
        "The train data \n",
        "\n",
        "The classification is done by three different methodologies:\n",
        "       1: Random Forest \n",
        "       2: Support vector machine\n",
        "       3: Logistic regression\n",
        "The model wil be trained on 80% of data and tested on 20%. All the fitted models  will be validated by using a 10-fold cross validation on  traning set.\n",
        "After fitting the model and selecting best model with higher accuracy, the model will be used to predict land covers on a WV3 (2017) imagery.\n",
        "\n",
        "\n",
        "## Procedures\n",
        "*   import data and training data\n",
        "*   preprocess the data\n",
        "*   build the models and functions\n",
        "*   validate the trained model by 10-fold cross validation\n",
        "*   evaluate the model on test set\n",
        "*   classify 2017 imagery by using model with highest accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JsuJTBnHBxV"
      },
      "source": [
        "# Just used for google colab, if you are not using google colab comment this code\n",
        "! pip install geopandas rasterio matplotlib descartes scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUzroWNdPvMo"
      },
      "source": [
        "Dataset\n",
        "===================================\n",
        "import:\n",
        "1= shapefile of the training dataset which contain classification of land covers\n",
        "2=  World veiew 2 imagery of the arctic region with 8 bands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpBQ0HNYOOWT"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOgPVahUXvsP"
      },
      "source": [
        "Import al the libraries used for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuNfh3raQUZr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gdal\n",
        "import random\n",
        "import math\n",
        "import itertools\n",
        "import rasterio\n",
        "from rasterio.plot import adjust_band\n",
        "import matplotlib.pyplot as plt\n",
        "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
        "from rasterio.plot import show\n",
        "from rasterio.windows import Window\n",
        "import rasterio.features\n",
        "import rasterio.warp\n",
        "import rasterio.mask\n",
        "from pyproj import Proj, transform\n",
        "from tqdm import tqdm\n",
        "from shapely.geometry import Polygon\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from shapely.geometry import mapping\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXLnnE8qOzXF"
      },
      "source": [
        "Analyze the main world view 2 imagery."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMnD6wXDQa7g"
      },
      "source": [
        "import os \n",
        "image_dir = '/content/drive/My Drive/classification/'\n",
        "\n",
        "# find every file in the  directory\n",
        "image_paths = [os.path.join(image_dir, '2010_WV2_WGS84.tiff') ]\n",
        "\n",
        "image_wv2 = image_dir + '2010_WV2_WGS84.tiff'\n",
        "dataset = rasterio.open(image_wv2, dtype='float32')\n",
        "img_rows, img_cols = dataset.shape\n",
        "img_bands =dataset.count\n",
        "print(dataset.shape) # dimensions\n",
        "print(dataset.count)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK-faw0BJOlk"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmFZhQKjkCkt"
      },
      "source": [
        "Read in the training labels image which represents 4 classes in the case study:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brSH-6N-sZyx"
      },
      "source": [
        "train2010=gpd.read_file('/content/drive/My Drive/classification/train2010_scrs_wv2.shp')\n",
        "\n",
        "geoms = train2010.geometry.values \n",
        "\n",
        "geometry = geoms[0] \n",
        "print(type(geometry))\n",
        "print(geometry)\n",
        "\n",
        "#  to GeoJSON format\n",
        "from shapely.geometry import mapping\n",
        "alltrains = [mapping(geometry)]\n",
        "print(alltrains)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5VuIB-cUXtw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADaQunXyVxCb"
      },
      "source": [
        "In this section:\n",
        "\n",
        "1:Calculate NDVI and NDWI.\n",
        "We will add these to variables to the model for classification as a feature.\n",
        "\n",
        "2: stack all the latyes to array which contains all bands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZINT0djTsI3"
      },
      "source": [
        "# ignore  \"divide by zero\" or \"divide by NaN\"\n",
        "np.seterr(divide='ignore', invalid='ignore')\n",
        "wv2_2010=rasterio.open('/content/drive/My Drive/classification/2010_WV2_WGS84.tiff')\n",
        "wv2_2010_img=wv2_2010.read()\n",
        "\n",
        "\n",
        "#1 claculate ndvi and ndwi and save them in a directory: first we define the function and then calculate ndvi and ndwi\n",
        "def calculate_ndvi(imagery):\n",
        "    NIR_Band=imagery[7,:,:]\n",
        "    Red_Band=imagery[5,:,:]\n",
        "    ndvi = np.clip((NIR_Band.astype(np.float16) - Red_Band.astype(np.float16)) / (NIR_Band.astype(np.float16) + Red_Band.astype(np.float16)), -1,1)\n",
        "    ndviDire=rasterio.open('../content/drive/My Drive/classification/newdata/newbands/ndvi.tiff', 'w', driver='Gtiff',width=wv2_2010.width,height=wv2_2010.height,count=1,crs=wv2_2010.crs,dtype='float16')\n",
        "    ndviDire.write(ndvi,1)\n",
        "    return ndvi\n",
        "\n",
        "def calculate_ndwi(imagery):\n",
        "    NIR_Band=imagery[7,:,:]\n",
        "    Green_Band=imagery[3,:,:]\n",
        "    ndwi = np.clip((Green_Band.astype(np.float16) - NIR_Band.astype(np.float16))/ (Green_Band.astype(np.float16)+ NIR_Band.astype(np.float16)), -1,1)\n",
        "    ndwiDire=rasterio.open('../content/drive/My Drive/classification/newdata/newbands/ndwi.tif', 'w', driver='Gtiff',width=wv2_2010.width,height=wv2_2010.height,count=1,crs=wv2_2010.crs,dtype='float16')\n",
        "    ndwiDire.write(ndwi,1)\n",
        "    return ndwi\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  3: stack all the bands in the directory\n",
        "\n",
        "    #call all the features in the directory\n",
        "all_features = '/content/drive/My Drive/classification/newdata/newbands'\n",
        "band_paths = [os.path.join(all_features, f) for f in os.listdir(all_features) if os.path.isfile(os.path.join(all_features, f))]\n",
        "band_paths.sort()\n",
        "band_paths\n",
        "    \n",
        "    \n",
        "    #create a layer for writing all the raster bands in the directory\n",
        "All_features = all_features + 'All_bands.tif'\n",
        "\n",
        "with rasterio.open(band_paths[0]) as src0:\n",
        "    meta = src0.meta\n",
        "# Update  the number of layers\n",
        "\n",
        "meta.update(count = len(band_paths))\n",
        "\n",
        "# Read each layer and write it to stack\n",
        "with rasterio.open(All_features, 'w', **meta) as dst:\n",
        "    for id, layer in enumerate(band_paths, start=1):\n",
        "        with rasterio.open(layer) as src1:\n",
        "            dst.write_band(id, src1.read(1))\n",
        "\n",
        "\n",
        "full_dataset_new = rasterio.open(All_features)\n",
        "img_rows, img_cols = full_dataset_new.shape\n",
        "img_bands = full_dataset_new.count\n",
        "print(full_dataset_new.shape) # dimensions\n",
        "print(full_dataset_new.count) # bands\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFsXqCvWoJEs"
      },
      "source": [
        "import rasterio as rio\n",
        "train2010=rio.open(\"train2010.tif\")\n",
        "coundband_2010=train2010.count\n",
        "train2010_img=train2010.read()\n",
        "unique, counts = np.unique(train2010_img, return_counts=True)\n",
        "#list(zip(unique, counts))\n",
        "#fig, ax = plt.subplots(figsize=(10, 10))\n",
        "# we then use these objects to draw-on and manipulate our plot\n",
        "#ax.imshow(train2010_img[0])\n",
        "train2010.crs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ndvi=rasterio.open('/content/drive/My Drive/classification/newdata/ndvi.tiff')\n",
        "ndwi=rasterio.open('/content/drive/My Drive/classification/newdata/ndwi.tif')\n",
        "allbands=rasterio.open('/content/drive/My Drive/classification/newdata/allbands.tiff')\n",
        "\n",
        "import rasterio\n",
        "\n",
        "file_list = [ndvi, ndwi, allbands]\n",
        "\n",
        "out_img = \"stack.tif\"\n",
        "stack=rasterio.open('/content/drive/My Drive/classification/newdata/stack.tif')\n",
        "print(stack.count)\n",
        "\n",
        "\n",
        "out_meta = ndvi.meta.copy()\n",
        "out_meta.update({\"count\": 10,\"nodata\": -10000})\n",
        "with rasterio.open(out_img, 'w', **out_meta) as dest:\n",
        "    for band_nr, src in enumerate(file_list, start=1):\n",
        "        dest.write(src, band_nr, indexes=10)\n",
        "\n",
        "stack=rasterio.open('/content/drive/My Drive/classification/newdata/stack.tif')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTXM3dV3cEzO"
      },
      "source": [
        "Visulize the imagery and new features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhFeRlx4XoQs"
      },
      "source": [
        "from rasterio.plot import show\n",
        "bands = np.array([5, 3, 2])\n",
        "colors_image = wv2_2010_img[bands, :, :].astype(np.float64)\n",
        "\n",
        "# rasters are in the format [bands, rows, cols] whereas images are typically [rows, cols, bands]\n",
        "rasterio.plot.show(colors_image)\n",
        "rasterio.plot.show(ndwi,cmap='RdYlGn')\n",
        "\n",
        "\n",
        "\n",
        "#mask data\n",
        "\n",
        "out_image, out_transform = mask(dataset, alltrains, crop=True)\n",
        "out_image.shape\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mcum4yLsZUA"
      },
      "source": [
        "Now  get the pixels from the World view2 imagery as outlined in each traininig shapefile.\n",
        "Our training data contains one main field:\n",
        "\n",
        "a  field which contains class names in String datatype.\n",
        "\n",
        "\n",
        "However, in order to pair up our vector data with our raster pixels, we will need a way of co-aligning the datasets in space which can be done by a function called mask in rasterio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYkD_KnFPA3o"
      },
      "source": [
        "Let's Start the journey \n",
        "==========================\n"
      ]
    }
  ]
}